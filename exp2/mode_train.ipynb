{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        \n",
    "        # first set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # second set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        return model\n",
    "\n",
    "# Example usage:\n",
    "model = LeNet.build(width=32, height=32, depth=3, classes=10)\n",
    "\n",
    "# Generate a plot of the model\n",
    "plot_model(model, to_file='lenet_architecture.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This network is based on the Line Follower Robot using CNN by Nawaz Ahmad\n",
    "# towardsdatascience.com\n",
    "#\n",
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "if version.parse(tf.__version__) < version.parse(\"2.9.0\"):\n",
    "    from keras.preprocessing.image import img_to_array\n",
    "else:\n",
    "    from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "  @staticmethod\n",
    "  def build(width, height, depth, classes):\n",
    "    # initialize the model\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "# first set of CONV => RELU => POOL layers\n",
    "    model.add(Conv2D(20, (5, 5), padding=\"same\",\n",
    "      input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# second set of CONV => RELU => POOL layers\n",
    "    model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation(\"relu\"))\n",
    "# softmax classifier\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "# return the constructed network architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "dataset = './trainImages/'\n",
    "\n",
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "# extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    # print(label)\n",
    "    if label == 'left':\n",
    "        label = 0\n",
    "    elif label == 'forward':\n",
    "        label = 1\n",
    "    else:\n",
    "        label =2\n",
    "    labels.append(label)\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "    labels, test_size=0.25, random_state=42)\n",
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=3)\n",
    "testY = to_categorical(testY, num_classes=3)\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mafu/miniforge3/envs/ros_env_2/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-12-15 17:43:31.348811: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-12-15 17:43:31.348869: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-12-15 17:43:31.348874: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-12-15 17:43:31.348908: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-15 17:43:31.348930: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=64, height=64, depth=3, classes=3)\n",
    "\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=INIT_LR,\n",
    "    decay_steps=EPOCHS,\n",
    "    decay_rate=0.96\n",
    ")\n",
    "opt = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 16:07:08.866854: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 46ms/step - accuracy: 0.8358 - loss: 0.4331 - val_accuracy: 0.8862 - val_loss: 0.2688\n",
      "Epoch 2/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 45ms/step - accuracy: 0.8842 - loss: 0.2736 - val_accuracy: 0.8964 - val_loss: 0.2321\n",
      "Epoch 3/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 45ms/step - accuracy: 0.9033 - loss: 0.2357 - val_accuracy: 0.8981 - val_loss: 0.2357\n",
      "Epoch 4/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 46ms/step - accuracy: 0.9127 - loss: 0.2108 - val_accuracy: 0.9194 - val_loss: 0.1931\n",
      "Epoch 5/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 46ms/step - accuracy: 0.9232 - loss: 0.1919 - val_accuracy: 0.9331 - val_loss: 0.1722\n",
      "Epoch 6/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 46ms/step - accuracy: 0.9319 - loss: 0.1727 - val_accuracy: 0.9376 - val_loss: 0.1673\n",
      "Epoch 7/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 46ms/step - accuracy: 0.9416 - loss: 0.1497 - val_accuracy: 0.9411 - val_loss: 0.1513\n",
      "Epoch 8/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - accuracy: 0.9457 - loss: 0.1412 - val_accuracy: 0.9432 - val_loss: 0.1453\n",
      "Epoch 9/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - accuracy: 0.9506 - loss: 0.1294 - val_accuracy: 0.9456 - val_loss: 0.1383\n",
      "Epoch 10/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - accuracy: 0.9508 - loss: 0.1264 - val_accuracy: 0.9467 - val_loss: 0.1332\n",
      "Epoch 11/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - accuracy: 0.9502 - loss: 0.1244 - val_accuracy: 0.9494 - val_loss: 0.1322\n",
      "Epoch 12/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - accuracy: 0.9554 - loss: 0.1202 - val_accuracy: 0.9500 - val_loss: 0.1289\n",
      "Epoch 13/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - accuracy: 0.9578 - loss: 0.1138 - val_accuracy: 0.9511 - val_loss: 0.1296\n",
      "Epoch 14/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - accuracy: 0.9576 - loss: 0.1120 - val_accuracy: 0.9511 - val_loss: 0.1264\n",
      "Epoch 15/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - accuracy: 0.9576 - loss: 0.1103 - val_accuracy: 0.9507 - val_loss: 0.1258\n",
      "Epoch 16/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 56ms/step - accuracy: 0.9584 - loss: 0.1114 - val_accuracy: 0.9511 - val_loss: 0.1255\n",
      "Epoch 17/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 58ms/step - accuracy: 0.9569 - loss: 0.1111 - val_accuracy: 0.9523 - val_loss: 0.1252\n",
      "Epoch 18/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 59ms/step - accuracy: 0.9583 - loss: 0.1091 - val_accuracy: 0.9515 - val_loss: 0.1250\n",
      "Epoch 19/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 60ms/step - accuracy: 0.9612 - loss: 0.1062 - val_accuracy: 0.9525 - val_loss: 0.1248\n",
      "Epoch 20/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 61ms/step - accuracy: 0.9586 - loss: 0.1094 - val_accuracy: 0.9527 - val_loss: 0.1247\n",
      "Epoch 21/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 61ms/step - accuracy: 0.9578 - loss: 0.1105 - val_accuracy: 0.9525 - val_loss: 0.1245\n",
      "Epoch 22/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 63ms/step - accuracy: 0.9602 - loss: 0.1073 - val_accuracy: 0.9527 - val_loss: 0.1245\n",
      "Epoch 23/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 66ms/step - accuracy: 0.9607 - loss: 0.1064 - val_accuracy: 0.9525 - val_loss: 0.1245\n",
      "Epoch 24/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 66ms/step - accuracy: 0.9595 - loss: 0.1083 - val_accuracy: 0.9525 - val_loss: 0.1244\n",
      "Epoch 25/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 66ms/step - accuracy: 0.9601 - loss: 0.1045 - val_accuracy: 0.9525 - val_loss: 0.1244\n",
      "Epoch 26/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 67ms/step - accuracy: 0.9589 - loss: 0.1076 - val_accuracy: 0.9525 - val_loss: 0.1244\n",
      "Epoch 27/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 68ms/step - accuracy: 0.9588 - loss: 0.1094 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 28/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 70ms/step - accuracy: 0.9574 - loss: 0.1106 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 29/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 68ms/step - accuracy: 0.9588 - loss: 0.1089 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 30/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 65ms/step - accuracy: 0.9600 - loss: 0.1054 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 31/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 66ms/step - accuracy: 0.9574 - loss: 0.1099 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 32/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 68ms/step - accuracy: 0.9591 - loss: 0.1089 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 33/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 68ms/step - accuracy: 0.9554 - loss: 0.1124 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 34/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 67ms/step - accuracy: 0.9592 - loss: 0.1073 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 35/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 64ms/step - accuracy: 0.9588 - loss: 0.1086 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 36/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 68ms/step - accuracy: 0.9603 - loss: 0.1079 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 37/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 66ms/step - accuracy: 0.9581 - loss: 0.1077 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 38/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 65ms/step - accuracy: 0.9563 - loss: 0.1129 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 39/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 69ms/step - accuracy: 0.9570 - loss: 0.1088 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 40/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 66ms/step - accuracy: 0.9566 - loss: 0.1103 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 41/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 64ms/step - accuracy: 0.9592 - loss: 0.1113 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 42/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 63ms/step - accuracy: 0.9601 - loss: 0.1080 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 43/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 63ms/step - accuracy: 0.9569 - loss: 0.1120 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 44/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 63ms/step - accuracy: 0.9581 - loss: 0.1094 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 45/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 63ms/step - accuracy: 0.9587 - loss: 0.1092 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 46/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 65ms/step - accuracy: 0.9576 - loss: 0.1098 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 47/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 79ms/step - accuracy: 0.9592 - loss: 0.1093 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 48/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 71ms/step - accuracy: 0.9590 - loss: 0.1068 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 49/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 88ms/step - accuracy: 0.9575 - loss: 0.1105 - val_accuracy: 0.9525 - val_loss: 0.1243\n",
      "Epoch 50/100\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 103ms/step - accuracy: 0.9602 - loss: 0.1050 - val_accuracy: 0.9525 - val_loss: 0.1243\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',       # Metric to monitor (e.g., validation loss)\n",
    "    patience=10,              # Number of epochs with no improvement after which training will stop\n",
    "    restore_best_weights=True # Restore model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# Training the model with early stopping\n",
    "H = model.fit(\n",
    "    trainX, trainY,\n",
    "    batch_size=BS,\n",
    "    validation_data=(testX, testY),\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save('models_h5/self_driving_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ros_env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
